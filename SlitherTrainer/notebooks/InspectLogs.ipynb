{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "eos",
   "display_name": "eos"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"../../data/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No file found, creating initial h5\n"
     ]
    }
   ],
   "source": [
    "def to_h5():\n",
    "    data = []\n",
    "    with open(DATA_DIR + \"/data.p\", \"rb\") as f:\n",
    "        while True:      \n",
    "            try:  \n",
    "                data += [pickle.load(f)]\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    # stack like types together\n",
    "    nextImages = []\n",
    "    currentImages = []\n",
    "    metadata = []\n",
    "    ids = []\n",
    "\n",
    "    for record in data:\n",
    "        nextImages.append(record['nextImage'])\n",
    "        currentImages.append(record['currentImage'])\n",
    "        metadata.append([\n",
    "            record['action'], record['reward'], int(record['died']), record[\"didBoost\"]\n",
    "        ])\n",
    "        ids.append(record.get('id', b\"00000000-0000-0000-0000-000000000000\"))\n",
    "\n",
    "    nextImages = np.array(nextImages)\n",
    "    currentImages = np.array(currentImages)\n",
    "    metadata = np.array(metadata)\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    assert nextImages.shape == currentImages.shape\n",
    "    assert metadata.shape[0] == nextImages.shape[0]\n",
    "\n",
    "    try:\n",
    "        # read in existing and append\n",
    "        with h5py.File(DATA_DIR + '/preprocessed.h5','r') as hf:\n",
    "            nextImages = np.vstack((hf['nextImage'][...], nextImages))\n",
    "            currentImages = np.vstack((hf['currentImage'][...], currentImages))\n",
    "            metadata = np.vstack((hf['metadata'][...], metadata))\n",
    "            ids = np.vstack((hf['ids'][...], ids))\n",
    "    except (FileNotFoundError, OSError):\n",
    "        print(\"No file found, creating initial h5\")\n",
    "        pass\n",
    "\n",
    "    # write new\n",
    "    with h5py.File(DATA_DIR + '/preprocessed.h5','w') as hf:\n",
    "        hf.create_dataset('currentImage', data=currentImages)\n",
    "        hf.create_dataset('nextImage', data=nextImages)\n",
    "        hf.create_dataset('metadata', data=metadata)\n",
    "        hf.create_dataset(\"ids\", data=ids)\n",
    "\n",
    "    \n",
    "to_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}